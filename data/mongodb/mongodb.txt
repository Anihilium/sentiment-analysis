this was just a test.
lol ;)
Looks like a typo here:http://github.com/mongodb/mongo/commit/2b7eb102159a36129222afa1883ea3b15145e08b#L0R40See &7 instead of &&
Bravo :)
Good to see I'm not the only one improving error messages!
Is it necessarily a good idea to have class diagrams in the visual studio projects? These projects will always be an afterthought (and rightly so) to the scons project.
that's an accident.will remove.
Confirmed that actually worked.
Shouldn't the constant MaxBSONObjectSize be used instead? In case one wants to customize the size.
stoll() doesn't exist in Visual Studio 2008. I'm installing the windows 7 SDK to see if that will rectify it, but perhaps even being dirty and calling atol() would be better than causing build problems.
The older, more conservative function is _strtoi64()Fix in http://github.com/zippy1981/mongo/commit/f7b7c07e2a72011b8dbd72d10dcbaa22d8e5fb54Stackoverflow discussion is in http://stackoverflow.com/questions/3106026/is-there-a-stoll-stroll-string-to-long-long-alternative-in-visual-studio-20/3106060#3106060
Test code I used for this.:<pre>#include <stdio.h>#include <stdlib.h>#include <string>namespace mongo {inline void uasserted(int msgid , char* msg) { printf("Msg: %s", msg); exit(4); }/* "user assert".if asserts, user did something wrong, not our code */#define MONGO_uassert(msgid, msg, expr) (void)( (!!(expr)) || (mongo::uasserted(msgid, msg), 0) )#define uassert MONGO_uassertinline long long parseLL( const char *n );// expect that n contains a base ten number and nothing else after it// NOTE win version hasn't been tested directlyinline long long parseLL( const char *n ) {long long ret;uassert( 13307, "cannot convert empty string to long long", *n != 0 );#if !defined(_WIN32)char *endPtr = 0;errno = 0;ret = strtoll( n, &endPtr, 10 );uassert( 13305, "could not convert string to long long", *endPtr == 0 && errno == 0 );#else#if _MSC_VER>=1600size_t endLen = 0;try {ret = std::stoll( n, &endLen, 10 );} catch ( ... ) {endLen = 0;}uassert( 13306, "could not convert string to long long", endLen != 0 && n[ endLen ] == 0 );#else // stoll() wasn't introduced into VS 2010.char* endPtr = (char *)&n[strlen(n) - 1];try {ret = _strtoi64( n, &endPtr, 10 );} catch ( ... ) {endPtr = 0;}uassert( 13310, "could not convert string to long long", *endPtr == 0 );#endif // _MSC_VER >= 16#endif // !defined(_WIN32)return ret;}}void main () {//printf("_MSC_VER: %d\n", _MSC_VER);char szNumber[] = "999999999";printf("number '%s': %d\n\n", szNumber, mongo::parseLL(szNumber));char szNumberWhitespace[] = "999999999999";printf("number '%s': %d\n\n", szNumberWhitespace, mongo::parseLL(szNumberWhitespace));char szNumberBad[] = "99r9dd999999";printf("number '%s': %d\n\n", szNumberBad, mongo::parseLL(szNumberBad));}</pre>
Dwight,Shouldn't we also check the error cases?I'll confess I'm not running the unit tests on my machine. I'll start doing that.
sure.UnitTest is something that runs at every server startup.so they must very light and fast."real" tests should go in dbtests / test binary (or jstests if applicable)running tests v good idea.see "smoke" page on wiki
The UTF-8 BOM, signifying nothing, and annoying the hell out of developers and users.
Was the near/far thing a 64 bit thing? I though the near/far dated back to win16 programming?Regardless, it compiles.
vs2008 vs vs2010 issue
don't comment out the lines in the method, just comment out doTest() etc...makes it easer to test, etc...
Eliot, please roll this commit back. I found a bug with it. I didn't think you would include it until I made a pull request to you. Thanks, Tony
Wouldn't "-o -" be more inline with unix convention than "-o stdout"? Or is the problem boost parsing?Then again, part of me thinks default mongodump behavior should be to stdout, and there shoulld be a new switch for current default behavior.
Double build break, double my bad. I'll have to start building on ubuntu to check these things.
Won't this catch use of small oplog size when used with an arbiter? In your docs you recommend using a small oploghttp://www.mongodb.org/display/DOCS/Adding+an+Arbiter
right.will take it out.
Could InterLockedExchange be used on windows and __sync_xor_and_fetch when GCC is used?For windows:http://msdn.microsoft.com/en-us/library/ms683590(v=vs.85).aspxFor GCC:http://gcc.gnu.org/onlinedocs/gcc/Atomic-Builtins.html
There is no way to make it cleaner using boost::filesystem ?http://www.boost.org/doc/libs/1_45_0/libs/filesystem/v2/doc/index.htm
detects int overflow in passed 2d bounds/parameters
Major change here is basically to pull up the expand algorithm into the superclass.
You also need to make a similar change within void ReplicaSetMonitor::_checkHosts():Line 297: log(1) << "updated set (" << _name << ") to: " << getServerAddress()Perhaps more places as well.
The one you mentioned should be that way i believe.
Why not checking that scale is a multiple of 1024 ?
Won't this mean you can step down a primary (and assuming a busy website load) 10 seconds of data may be lost?I would have thought you would want to have no lag what so ever, otherwise you need to specify force: true, instead of allowing 10 seconds of lag time?
> Won't this mean you can step down a primary (and assuming a busy website> load) 10 seconds of data may be lost?Assuming a healthy network, no.The other secondaries will replicate fromthe primary until they are up-to-date, then elect a new primary.The 10second rule is to make sure that there isn't a long lag while secondariesare catching up (and there is no primary).If the network is unhealthy, then it is possible that data will be rolledback (not lost).However, this was true before, is part of the design ofreplica sets (seehttp://www.mongodb.org/display/DOCS/Replica+Set+Design+Concepts), and thiscommit provides a stronger guarantee than before: only 10 seconds of datamay be rolled back.On Sat, Apr 9, 2011 at 11:35 PM, Plasma <reply@reply.github.com>wrote:> Won't this mean you can step down a primary (and assuming a busy website> load) 10 seconds of data may be lost?>> I would have thought you would want to have no lag what so ever, otherwise> you need to specify force: true, instead of allowing 10 seconds of lag time?> ##>> Reply to this email directly or view it on GitHub:>> https://github.com/mongodb/mongo/commit/6af8365495692b330f1ec8a93c5f172817f7a7c3#commitcomment-335801
Ah that makes a lot of sense now.I initially thought that the 10 seconds was a tolerance of how much data you could lose if you wanted to switch primaries (that's what I get from only glancing at the code!).I thought that a stepdown would immediately stop any secondaries from syncing from it (and they could be at most 10 seconds out of date) and then a new primary would be elected within a few seconds (at the cost of maybe losing yet-to-be-synced data from the previous primary).If I am correct in reading your comment then it then sounds like its much smarter than that; and instead the primary steps down, lets the secondaries continue to sync from it to become up to date (so no data is lost, even if the data was not yet synced from the primary), and then a new primary is elected without data loss.The 10 second window is just a way to make sure this 'catch up' process will happen fast (as not much data needs to be synced) as to not delay election of a new primary.Thanks for clearing that up!
> If I am correct in reading your comment then it then sounds like its much> smarter than that; and instead the primary steps down, lets the secondaries> continue to sync from it to become up to date (so no data is lost, even if> the data was not yet synced from the primary), and then a new primary is> elected without data loss.>> The 10 second window is just a way to make sure this 'catch up' process> will happen fast (as not much data needs to be synced) as to not delay> election of a new primary.Yes, exactly.Thanks for clearing that up!No problem!On Sun, Apr 10, 2011 at 6:36 PM, Plasma <reply@reply.github.com>wrote:> Ah that makes a lot of sense now.>> I initially thought that the 10 seconds was a tolerance of how much data> you could lose if you wanted to switch primaries (that's what I get from> only glancing at the code!).>> I thought that a stepdown would immediately stop any secondaries from> syncing from it (and they could be at most 10 seconds out of date) and then> a new primary would be elected within a few seconds (at the cost of maybe> losing yet-to-be-synced data from the previous primary).>> If I am correct in reading your comment then it then sounds like its much> smarter than that; and instead the primary steps down, lets the secondaries> continue to sync from it to become up to date (so no data is lost, even if> the data was not yet synced from the primary), and then a new primary is> elected without data loss.>> The 10 second window is just a way to make sure this 'catch up' process> will happen fast (as not much data needs to be synced) as to not delay> election of a new primary.>> Thanks for clearing that up!> ##>> Reply to this email directly or view it on GitHub:>> https://github.com/mongodb/mongo/commit/6af8365495692b330f1ec8a93c5f172817f7a7c3#commitcomment-336498
perhaps, this would extend "life" for SERVER-3016 issues ?
OMG thank you for fixing this.Personally a victim of it. :)
Haha, you're welcome :)
backport?
The formatting on this is off.Also, this will be kind of slow since its going to cause an error every time.We need to check and see if there actually is a prompt() function.
Should make it possible to write "uassert( 0, "blah blah", x > 3 );", which will then get translated on first build / first errorcode check to uassert( <next errorcode>, "blah blah", x > 3 );"
alloc deleted freelist allocation chaining
Damn, I'm glad I'm not as stupid as the guy who wrote this.
that's harsh :-)what's wrong with it
assert is not normally used for buffer overflow protection (as it appears to be in this diff) as it's a macro that doesn't generate any code without NDEBUG defined.However, it appears assert is redefined as MONGO_assert which may properly guard this function even when not compiled with debugging? I couldn't quickly find the definition of MONGO_assert...At any rate the standard approach in this case would be to use the strncpy function which only copies up to len bytes. The strcpy/strncpy man page even includes a sample implementation of strncpy.
in mongo assert is defined even in release builds.thus this works.the idea is that this notifies if the buffer is too small.strncpy would work but you wouldn't get any notification.this should never happen thus the abort.
Excellent. Disaster averted.I think this commit just got passed around because it's very difficult to tell that assert has non-default behavior.
I believe it was passed around as a pre-fix copy of it was found in a thirdparty driver and mistaken for being mongoDB code.Should be corrected inboth places now.On Tue, Jul 19, 2011 at 4:53 PM, schmichael <reply@reply.github.com>wrote:> Excellent. Disaster averted.>> I think this commit just got passed around because it's very difficult to> tell that assert has non-default behavior.> ##>> Reply to this email directly or view it on GitHub:>> https://github.com/mongodb/mongo/commit/8b930cb852f4b9eb68036fb3db2ec21568cdb943#commitcomment-485791
what's wrong with assert? it works doesn't it?
I believe it was passed around because apparently this engineer never heard of strncpy(3).
it means that the db will allocate 3GB right off the bat and take a while to start.May be quite painful for someone just testing the db.I guess we'll have to remember to tell people to use --smallfiles when trying out mongo.
This line does not affect mongodb parameters in Debian.Admin should create /etc/default/mongo or hotfix start/stop script.
The same as dbpath — does not affect mongodb parameters in Debian.Admin should create /etc/default/mongo or hotfix start/stop script.
This loop only iterates twice but the sleep time is one-third, thus only sleeping two-thirds all together. Is this intended?
It seems odd to me to have non deterministic tests.This code seems like it could lead to a test failing one time and succeeding when you try it again.
I agree!Just added https://github.com/mongodb/mongo/commit/1450e4ccdf72c77f9e5b8d037bcaff732d863ab3 to remove the non-determinism.
SERVER-3717 (typo)
I don't know if it is ok to add comments here, if not I'm sorry and won't do it again.This makes my build fail saying that thread-local is not supported for this target which is true because osx doesn't support __threadAdding !defiled(__MACH\__) makes osx use thread_specific_ptr. I'm using osx Lion and building with no args.Feel free to delete the comment :)
thanks - just pushed an attempted fix.
i.e. use query option oplog replay which can efficiently find starting position in a very large oplog when querying GTE
I'm not sure if this is necessary. Write locks are greedy so a secondary is more likely to starve reads than the sync thread.To keep replication up-to-date, we really need a way of prioritizing the oplog-reading thread on the primary.
Would the try/catch be better in _addWriteBack?
please use real names.Client::GodScope godScope;
see coding styleif () {}else {}
This is a rather odd decision, but I suppose there are reasons behind them.
Bad Scott! Bad!
Should it only do this for a replica set and not Master/Slave?
test message
we need to be able to run single files directly - so we need load.js in there
Would be great to break this up a bit.Too late now - but there is some refactoring and some real changes.
Shouldn't we also globally replace RS_SHUNNED with RS_REMOVED ?
would be nice to break these up...especially since the bson one is potentially large
Why did you add the copy and assignment ops? I think those are the same as the automatically generated ones.
I checked in the debugger, and it turns out they're not. It appears to have been doing bitwise copies. I don't understand why the compiler didn't complain about requiring a real copy ctor needing to be defined.> --->> From: Mathias Stearn reply@reply.github.com> To: Chris Westin cwestin@yahoo.com> Sent: Tuesday, February 14, 2012 6:56 PM> Subject: Re: [mongo] first cut at named traces (unused); copy ctor and assignment op for BSONObj (59e9b72)>> Why did you add the copy and assignment ops? I think those are the same as the automatically generated ones.> --->> Reply to this email directly or view it on GitHub:> https://github.com/mongodb/mongo/commit/59e9b72297906e68686c1ffeb2244736ecac945b#commitcomment-967692
Things got all piled up while we couldn't push anything.It turns out things were not copying BSONObj correctly before. If it turns out to cause problems, its just a couple of lines to undo it.> --->> From: Eliot reply@reply.github.com> To: Chris Westin cwestin@yahoo.com> Sent: Tuesday, February 14, 2012 6:49 PM> Subject: Re: [mongo] first cut at named traces (unused); copy ctor and assignment op for BSONObj (59e9b72)>> would be nice to break these up...> especially since the bson one is potentially large> --->> Reply to this email directly or view it on GitHub:> https://github.com/mongodb/mongo/commit/59e9b72297906e68686c1ffeb2244736ecac945b#commitcomment-967679
i guess that is a good addition anyway in the sense that lock+fsync is then better.
not sure exactly how this has evolved but originally the idea was that with ThreadSpanningOp when you use it, you use it only and it wasn't designed to interoperate with the other Lock:: classes and stuff.thus it didn't set threadstate for example.it is fine if it is different but does this now imply i can use ThreadSpanningOp interoperably with all the other Lock:: classes?i imagine it won't play nicely with them.will read more later.
Right. That doesn't work becUse other things rely on lock semantics.Seems to be working fine now though.On Mar 17, 2012, at 12:57 PM, Dwight Merrimanreply@reply.github.com wrote:> not sure exactly how this has evolved but originally the idea was that with ThreadSpanningOp when you use it, you use it only and it wasn't designed to interoperate with the other Lock:: classes and stuff.thus it didn't set threadstate for example.it is fine if it is different but does this now imply i can use ThreadSpanningOp interoperably with all the other Lock:: classes?i imagine it won't play nicely with them.will read more later.> --->> Reply to this email directly or view it on GitHub:> https://github.com/mongodb/mongo/commit/c949cad1fa6e4cb26693748b1751f4fd2e6113b8#commitcomment-1098166
The ifdefs need to be changed to make this work on Windows XP.
What's the nature of the conflict in the "using boost::shared_ptr" implementation?That fixed the win32 buildbot and is also used in other unit test files.Should those files be changed as well?
It sounds like either method will work right now, but there are some reasons to avoid 'using boost::shared_ptr'.
Given your use case, scoped_ptr?
This is semantically different then what was there before and not nearly as powerful.The old way with -v you can turn this on at start or runtime.Please change this back and the other one below.
see abovecould make LOG if performance was the concern
this should just besleepsecs( runner->config.seconds )
would it make any sense to do```if( X.n ) {X.c.notify_one();}```as an optimization?
It's a bit of a microoptimization, since there's nobody to spuriously wake up when X.n is 0, but it would not be incorrect semantically.
i agree if you are sure notify_one() is fast with no waiters.
This is going to give some pretty inaccurate stats in high-activity systems.We'll just lose a lot of times.At least label it with SERVER-5026.If you're willing to fix it now, so it doesn't underreport times when the system is heavily loaded, I'd implement an AtomicUint64 in bson/util/atomic_int.h, give it an operator+=, and be done with it.It'll have the same cache performance problems as this implementation, but will at least report correct times.
Call this "QLockTimingWrapper"?
Why here is just `_query.isEmpty()` instead of `_query.getFilter().isEmpty()` ?Like here https://github.com/mongodb/mongo/commit/d3d719c3aa72d63fe838f1e5eae7098e3bffe721#L0R95
this test is redundant. maybe you meant ax...|| bx... ?
Thanks, I will submit a fix to master for this shortly.
No plans to merge the auth part atleast to v2.0?
it should be done as of v2.0.1
I can only see this in master, no other branches :]
you're right.was only backported for mongostat, not mongotop.i'll look into it for 2.0.5
andy pulled it into 2.0.5 today.https://github.com/mongodb/mongo/commit/a55507d21e53970d324eef2cafc653aea648b885
uncomment this?
did later
@erh What do you think of the redis implementation of TTL? http://redis.io/commands/expire
Its hard to compare directly as the whole system is so different.On Fri, May 11, 2012 at 1:42 AM, Sid Upadhyayreply@reply.github.comwrote:> @erh What do you think of the redis implementation of TTL? http://redis.io/commands/expire> --->> Reply to this email directly or view it on GitHub:> https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318817
Oh ya for sure. Though I'm wondering why you chose an active method forexpiring the keys, as opposed to the more passive method used in redis.On Fri, May 11, 2012 at 12:44 AM, Eliot <reply@reply.github.com> wrote:>> Its hard to compare directly as the whole system is so different.>> On Fri, May 11, 2012 at 1:42 AM, Sid Upadhyay> reply@reply.github.com> wrote:>> > @erh What do you think of the redis implementation of TTL?> > http://redis.io/commands/expire> > ---> >> > Reply to this email directly or view it on GitHub:> >> > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318817> --->> Reply to this email directly or view it on GitHub:>> https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318826
From the docs, redis seems to do it both passively and actively.On Fri, May 11, 2012 at 2:16 AM, Sid Upadhyayreply@reply.github.comwrote:> Oh ya for sure. Though I'm wondering why you chose an active method for> expiring the keys, as opposed to the more passive method used in redis.>> On Fri, May 11, 2012 at 12:44 AM, Eliot <> reply@reply.github.com>> > wrote:> >> > Its hard to compare directly as the whole system is so different.> >> > On Fri, May 11, 2012 at 1:42 AM, Sid Upadhyay> > reply@reply.github.com> > wrote:> >> > > @erh What do you think of the redis implementation of TTL?> > > http://redis.io/commands/expire> > > ---> > >> > > Reply to this email directly or view it on GitHub:> > >> > > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318817> > ---> >> > Reply to this email directly or view it on GitHub:> >> > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318826> --->> Reply to this email directly or view it on GitHub:> https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318923
Ya, which is a pretty interesting choice with respect to performancetradeoffs. I'll have to build this version of mongo and play around with itto see what real performance tradeoffs there could be. Though I'm sure theypale in comparison to the value of TTL.On Fri, May 11, 2012 at 6:16 AM, Eliot <reply@reply.github.com> wrote:>> From the docs, redis seems to do it both passively and actively.>> On Fri, May 11, 2012 at 2:16 AM, Sid Upadhyay> reply@reply.github.com> wrote:>> > Oh ya for sure. Though I'm wondering why you chose an active method for> > expiring the keys, as opposed to the more passive method used in redis.> >> > On Fri, May 11, 2012 at 12:44 AM, Eliot <> > reply@reply.github.com> >> > > wrote:> > >> > > Its hard to compare directly as the whole system is so different.> > >> > > On Fri, May 11, 2012 at 1:42 AM, Sid Upadhyay> > > reply@reply.github.com> > > wrote:> > >> > > > @erh What do you think of the redis implementation of TTL?> > > > http://redis.io/commands/expire> > > > ---> > > >> > > > Reply to this email directly or view it on GitHub:> > >> > > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318817> > > ---> > >> > > Reply to this email directly or view it on GitHub:> > >> > > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318826> > ---> >> > Reply to this email directly or view it on GitHub:> >> > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318923> --->> Reply to this email directly or view it on GitHub:>> https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1319884
Would be great if you could run those tests and share results :)On Fri, May 11, 2012 at 1:43 PM, Sid Upadhyayreply@reply.github.comwrote:> Ya, which is a pretty interesting choice with respect to performance> tradeoffs. I'll have to build this version of mongo and play around with it> to see what real performance tradeoffs there could be. Though I'm sure they> pale in comparison to the value of TTL.>> On Fri, May 11, 2012 at 6:16 AM, Eliot <> reply@reply.github.com>> > wrote:> >> > From the docs, redis seems to do it both passively and actively.> >> > On Fri, May 11, 2012 at 2:16 AM, Sid Upadhyay> > reply@reply.github.com> > wrote:> >> > > Oh ya for sure. Though I'm wondering why you chose an active method for> > > expiring the keys, as opposed to the more passive method used in redis.> > >> > > On Fri, May 11, 2012 at 12:44 AM, Eliot <> > > reply@reply.github.com> > >> > > > wrote:> > > >> > > > Its hard to compare directly as the whole system is so different.> > > >> > > > On Fri, May 11, 2012 at 1:42 AM, Sid Upadhyay> > > > reply@reply.github.com> > > > wrote:> > > >> > > > > @erh What do you think of the redis implementation of TTL?> > > > > http://redis.io/commands/expire> > > > > ---> > > > >> > > > > Reply to this email directly or view it on GitHub:> > > >> > > > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318817> > > > ---> > > >> > > > Reply to this email directly or view it on GitHub:> > > >> > > > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318826> > > ---> > >> > > Reply to this email directly or view it on GitHub:> > >> > > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318923> > ---> >> > Reply to this email directly or view it on GitHub:> >> > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1319884> --->> Reply to this email directly or view it on GitHub:> https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1321463
Sure thing Eliot! I'll try to run some tests this evening with idle loadfor TTL jobs in the background, and I'll use the previous commit as thebaseline. Keep ya posted!On Fri, May 11, 2012 at 12:46 PM, Eliot <reply@reply.github.com> wrote:>> Would be great if you could run those tests and share results :)>> On Fri, May 11, 2012 at 1:43 PM, Sid Upadhyay> reply@reply.github.com> wrote:>> > Ya, which is a pretty interesting choice with respect to performance> > tradeoffs. I'll have to build this version of mongo and play around with> > it> > to see what real performance tradeoffs there could be. Though I'm sure> > they> > pale in comparison to the value of TTL.> >> > On Fri, May 11, 2012 at 6:16 AM, Eliot <> > reply@reply.github.com> >> > > wrote:> > >> > > From the docs, redis seems to do it both passively and actively.> > >> > > On Fri, May 11, 2012 at 2:16 AM, Sid Upadhyay> > > reply@reply.github.com> > > wrote:> > >> > > > Oh ya for sure. Though I'm wondering why you chose an active method> > > > for> > > > expiring the keys, as opposed to the more passive method used in> > > > redis.> > > >> > > > On Fri, May 11, 2012 at 12:44 AM, Eliot <> > > > reply@reply.github.com> > > >> > > > > wrote:> > > > >> > > > > Its hard to compare directly as the whole system is so different.> > > > >> > > > > On Fri, May 11, 2012 at 1:42 AM, Sid Upadhyay> > > > > reply@reply.github.com> > > > > wrote:> > > > >> > > > > > @erh What do you think of the redis implementation of TTL?> > > > > > http://redis.io/commands/expire> > > > > > ---> > > > > >> > > > > > Reply to this email directly or view it on GitHub:> > >> > > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318817> > >> > > > > ---> > > > >> > > > > Reply to this email directly or view it on GitHub:> > >> > > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318826> > >> > > > ---> > > >> > > > Reply to this email directly or view it on GitHub:> > >> > > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1318923> > > ---> > >> > > Reply to this email directly or view it on GitHub:> > >> > > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1319884> > ---> >> > Reply to this email directly or view it on GitHub:> >> > https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1321463> --->> Reply to this email directly or view it on GitHub:>> https://github.com/mongodb/mongo/commit/25bdc679a0e559d64ec7f22b0468cf5b1671c4e7#commitcomment-1321501
This was like this on purpose as their are different implementations.Please revert.
Why global lock?Is lock for collection only is not enough?
It's more work to determine which collection to lock, and this line is hit rarely if at all.
This is going to cause problems with other code in the server that assumes a certain format.Going to revert this part.
Oh snap! Hari K opening his sources!![Hari](http://farm2.staticflickr.com/1332/980464134_23807e3eb2.jpg)
That's not Hari! That man has hair!
Commit message should say _recvChunkCommit, not _recvChunkVersion
what'shappeningbefore
Typo in commit message - this actually fixes SERVER-8115.
what happened here?
Hi Hannes,```Text Search will be released with 2.4.It is presently available in```2.3.2.-POn Thu, Jan 31, 2013 at 4:15 PM, Hannes Magnussonnotifications@github.comwrote:> what happened here?>> —> Reply to this email directly or view it on GitHubhttps://github.com/mongodb/mongo/commit/f201972ecc87f099777e1c61f269998f4399caf4#commitcomment-2539781.
I mean with that specific word, it has several spaces which I imagine will break stuff.It should probably have been on a new line
the key should be pidfilepath
any plans on this getting merged in, i am running into maxconnection limits issues almost everyday.
We weren't planning to backport this change, but it's usually not a good idea to run with more than 20k conns.Have you looked into why your connection load is so heavy?
I am the sysadmin of a system that gets more then 20k connections a secondwe spike upto 60k/req a second. We have a 3 shard cluster with 3 members inthe replica set. The machines are fine they are amazon's cr1.8xlarge nodes.On May 26, 2013 2:48 PM, "Daniel Pasette" notifications@github.com wrote:> We weren't planning to backport this change, but it's usually not a good> idea to run with more than 20k conns. Have you looked into why your> connection load is so heavy?>> —> Reply to this email directly or view it on GitHubhttps://github.com/mongodb/mongo/commit/99e6e03543459cf6c4fea61dc6d3c9b4b2ba5ed3#commitcomment-3291673> .
SERVER-9497 is the ticket associated with this commit
This log message made my entire evening (during which I was harshly awoken and summoned to fix things). You are a hero, nay, a champion. I salute you.
Glad I could help, I guess!
Hi - just noted that the VC++ 2010 project still contains references to principal.cpp and wont build.
Excellent :)
should we enable this now?
Yes.Already spoken to greg about this.On Tue, Sep 17, 2013 at 6:16 AM, Gianfranco Palumbo <notifications@github.com> wrote:> should we enable this now?>> —> Reply to this email directly or view it on GitHubhttps://github.com/mongodb/mongo/commit/c34d5a987b25ec72b989077769435404ad7d3608#commitcomment-4110206> .
Great!
Whoot! Thanks Matt
This file doesn't exist anymore in the repo.I found lots of files still present on the VS2010 project file that changed location, or simply have been deprecated and don't exist anymore.The VS2010 project can't compile as is right, I can't say for sure, but probably there's about 50 files either missing or mislocated.I was trying to make it compile to fix a very bad issue regarding Windows kernel scheduler and timer resolution that cause tailable cursors to underperform unless there's another program running on the computer who has altered the resolution of Windows usingtimeBeginPeriod(n).What are the plans to fix the VS2010 solution file?
Are you planning to get this timedWaitToBeNotified() function back?
(cherry-picked from commit 6a3d6d0affbff6249caa50897dcbe325eb45aea9)
This is actually for SERVER-13753 I believe.
Is there a reason a new snapshot is created after committing a unit, instead of in beginUnitOfWork()?
Can you take a look at patch: https://reviews.facebook.net/D21381 and see whether the interface works for you?
Do you expect "status.IsNotFound()" is possible here? I assume the handling of corruption or IOException should be different from NotFound.
rocksdb::DB::GetLiveFilesMetaData() can return you information about the LSM tree, including each files' level and key range.
I cannot think of any way of doing that. What's the use case of that? We can consider whether adding something like can help.
Is a shorter separator possible with your key structure?
Usually, the best practice is to check _iterator.status() if it is not valid, and handle the case like corruption or IOException accordingly.
What's the problem of it?
 _checkStatus()?
This return value is a little bit confusing to me. KeyMayExist() does bloom filter check so that even true is returned, the key still may not exist in the DB. Is it what this comment line mean?
Hi, I'm glad to be able to see the progress. I have some inline comments.Another question: last Tuesday, I heard someone said that RecoveryUnit::isCommitNeeded() is going away. Is it still going to happen?
Is it merged already? If it is, can you point me the revision?
A question inline.
I think so, but it will take some experimentation to be sure.
No. The RecordID[1] passed in to RecordStore::updateRecord should always be valid. Inserting / upserting is handled in the higher level code.[1] RecordID is currently spelled DiskLoc, but we plan to change that soon.
I think that will cover the usecase for this function.
We have a user-facing "touch" command that allows users to preload specified data and/or indexes in to memory in an efficieint manner. For now leaving this as a no-op should be acceptable as it is for optimization, not correctness.
Probably in this case, but these IDs are only 8 bytes, so it may not buy too much. The index comparator would probably be a more usefull optimization, but it is trickier.Either way, seems like an optimization that can wait.
It is somewhat unclear what operations on an Iterator require checking status(). Why not just return a rocksdb::Status from the ones that do?
Once we commit the WriteBatch, all of its changes will now be visible on the new _snapshot. In a sense, it should be considered the "base" that the WriteBatch is on top of, in that "now" represents _snapshot + _writeBatch. We probably also need another Snapshot member that is the initial snapshot from when the operation began (an operation can be many UnitsOfWork). We are still figuring out what the correct API is to support snapshot-based storage engines as sometimes we need the "latest" copy of an object and sometimes the "original" is fine.
Need to decide if these should always be fatal or if there are some failure modes that are acceptable.
@RedBeard0531 the iterator interface comes from LevelDB. I don't know the answer:)
The return value is basically only used for corruption checking, as it should always be true (except for special cases involving background indexing where it is ignored entirely). We may be able to just remove the return value for this method.Basically, it is always ok for this function to return true (although index corruption may go unnoticed), but it should only return false when sure that the key doesn't exist since that can indicate an error.
@siying You may also be interested in https://github.com/mongodb/mongo/commit/e970e918c5300a13360edb57a88871b02dbe5982Yes, isCommitNeeded() and commitIfNeeded() will be going away soon. Possibly this week.
@RedBeard0531here is my understanding. A snapshot is technically correct from any time before the first read/write in a transaction (correct me if I'm wrong). The later the snapshot is declared, the performance of RocksDB is likely to be better, because outstanding snapshots during a RocksDB mem table flushing will force us to keep two copies. Seems to me that it will also better for MongoDB since it is less counter-intuitive for users.
@RedBeard0531 thanks. I'll take a look at https://github.com/mongodb/mongo/commit/e970e918c5300a13360edb57a88871b02dbe5982
Actually a snapshot is lazily constructed on first use at line 140 below. This is just "refreshing" the snapshot to reflect the WriteBatch we just committed so that _snapshot or _writeBatch will have the latest copy of anything we wrote to.
@RedBeard0531 can you give more context about why people want to do it? I understand that by issuing a touch before issuing the query, the extra query time will be reduced. But the total time that a user needs to spend on waiting is not reduced, right?Again, technically, it is technically possible for us to add a feature to warm to cache for a column family. Just try to understand the exact use case.
This isn't done inline with the query, it is a separate command. It is an ops-level operation that can be done (eg) after restarting a server for maintnance, or periodically on a secondary to keep it "hot" if all queries are going to the primary.Also this doesn't just preload for a query, it preloads the _entire_ collection and/or index. This allows it to do sequential IO rather than loading each object on demand. Therefore it can be _significantly_ faster than just waiting for the cache to be warmed by a query.
PS here is a post about it: http://blog.mongodb.org/post/44706549534/mongodb-tip-the-touch-command
@RedBeard0531probably I have some misunderstanding about how RecoveryUnit is used. In my understanding, after removing CommitIfNeeded(), one transaction will use one RecoveryUnit, which includes one snapshot and one write batch. commitUnitOfWork() will be called when committing one transaction, and the refreshed _snapshot will be used by the next transaction, if we want to reuse the recovery unit. Am I understand correctly?
The word "Transaction" is a bit loaded so lets avoid it for now. Consider a multi update that adds 5 "awesome points" to all users if today is their birthday. In mongo, that whole multi-update will use a single RecoveryUnit instance. However, a new WriteUnitOfWork will be created (on the single RU) and committed for each user that matches the query while we are updating thier object. This is because we only guarantee isolation and atomicity on each document, even when doing a multi-update.
Did I miss anything? In dropDatabase(), while _entryMapMutex is hold, closeDatabase() is called, where _dbCatalogMapMutex is hold?
lock _dataSizeLock is still hold here. Is it expected?
I don't understand. How is it possible unless there is a bug in RocksDB? Reverse Seek() returns !Valid(), should mean the look-up key is smaller than the smallest key in the DB. Did you see it happening?
Hi, this patch broke the build when RocksDB is enabled. Do you want to make sure storage/rocks is still buildable after changing the storage APIs?
why NULL here :(
This change seems to have broke my build.```scons: Reading SConscript files ...scons version: 2.0.1python version: 2 6 6 'final' 0AttributeError: 'module' object has no attribute 'TestCase':File "/data/users/icanadi/mongo/SConstruct", line 513:env = Environment(**envDict)File "/usr/lib/scons/SCons/Environment.py", line 991:apply_tools(self, tools, toolpath)File "/usr/lib/scons/SCons/Environment.py", line 105:env.Tool(tool)File "/usr/lib/scons/SCons/Environment.py", line 1691:tool = SCons.Tool.Tool(tool, toolpath, **kw)File "/usr/lib/scons/SCons/Tool/__init__.py", line 94:module = self._tool_module()File "/usr/lib/scons/SCons/Tool/__init__.py", line 109:return imp.load_module(self.name, file, path, desc)File "/data/users/icanadi/mongo/site_scons/site_tools/mongo_unittest.py", line 7:from buildscripts import smokeFile "/data/users/icanadi/mongo/buildscripts/smoke/__init__.py", line 4:import executorFile "/data/users/icanadi/mongo/buildscripts/smoke/executor.py", line 15:import testersFile "/data/users/icanadi/mongo/buildscripts/smoke/testers.py", line 18:class JSUnitTest(unittest.TestCase):```
_Summary:_If when pulling new code you run into problems using scons,remove the pre-existing "site_scons/site_tools/unittest.pyc" file from yoursource tree.It may cause a "module object has no attribute TestCase"error.One of the pluggable modules in our build's site_scons, "unittest.py",masks the existing "unittest" module.As of yesterday, we are nowimporting the standard unittest module into our builds, which causesproblems when there is a previously compiled module with the same name.This can cause a "module object has no attribute TestCase" error whenrunning scons targets.The solution is to remove the existing site_scons/site_tools/unittest.pycfile - the module has now been renamed to "mongo_unittest".On Fri, Sep 19, 2014 at 1:27 PM, Igor Canadi notifications@github.comwrote:> This change seems to have broke my build.>> scons: Reading SConscript files ...> scons version: 2.0.1> python version: 2 6 6 'final' 0> AttributeError: 'module' object has no attribute 'TestCase':> File "/data/users/icanadi/mongo/SConstruct", line 513:> env = Environment(*_envDict)> File "/usr/lib/scons/SCons/Environment.py", line 991:> apply_tools(self, tools, toolpath)> File "/usr/lib/scons/SCons/Environment.py", line 105:> env.Tool(tool)> File "/usr/lib/scons/SCons/Environment.py", line 1691:> tool = SCons.Tool.Tool(tool, toolpath, *_kw)> File "/usr/lib/scons/SCons/Tool/**init**.py", line 94:> module = self._tool_module()> File "/usr/lib/scons/SCons/Tool/__init__.py", line 109:> return imp.load_module(self.name, file, path, desc)> File "/data/users/icanadi/mongo/site_scons/site_tools/mongo_unittest.py", line 7:> from buildscripts import smoke> File "/data/users/icanadi/mongo/buildscripts/smoke/**init**.py", line 4:> import executor> File "/data/users/icanadi/mongo/buildscripts/smoke/executor.py", line 15:> import testers> File "/data/users/icanadi/mongo/buildscripts/smoke/testers.py", line 18:> class JSUnitTest(unittest.TestCase):>> —> Reply to this email directly or view it on GitHub> https://github.com/mongodb/mongo/commit/e88273ac940cdef9e12c94a6bdbd2694b706a635#commitcomment-7855033> .
Tnx @monkey101 !
Any reason why is this NULL here? RocksDB SIGSEGVs because it's expecting OperationContext.
Is there going to be another 2.6.5 release candidate?If so, can we get this included?
8192 Alignment size raized the fassert 16143 on my PPC systems, this is why I changed it in the first place.
Hi @corentinbaron,This is more of a reminder to ourselves. We were thinking of validating the numerical value of the block size itself - for example, that it should be a power of 2.Ben
Hi @lukebrowning,You should vote for the back port on:https://jira.mongodb.org/browse/SERVER-14835The **Backport** field has been set to _Requested_ - we periodically review all tickets requested for back port. If the ticket is approved (or rejected) for back port, you will see a corresponding change in the **Backport** field and the fix should show up in the next release.Regards,Ben
Under Centos 7, mongod is in /usr/bin
Thanks @benety !
I have to run this query `db.collection.distinct("user", {"method": "ImAMethod"})`I already indexed on `method` field, so my query is fully covered(is my query fully covered?), and I'm not able to see any improvement on the time if I index `user` field seperately.. or do I need to have an index that covers both `method` and `user` like `{user: 1, method: 1}` or `{method: 1, user: 1}`Right now its taking 3mins to get distinct users that satisfy the above query, around 12 million documents in my collection.. single 4GB machine..
@syllogismos, please take your question over to the [mongodb-user](https://groups.google.com/forum/#!forum/mongodb-user) mailing list. We use github exclusively for development related matters.
Ok. I will, thanks, just got excited I found the commit that I'm looking for.
After updating fedora or redhat system , with previous versions of mongod you may have this error :**_ERROR: Cannot write pid file to /var/run/mongodb/mongod.pid: No such file or directory**_If it happen for you patchyour /etc/init.d/mongod script following this commitWhy ?ReHat fedora, cent os...Fedora has changed how things works (breaking third party software...thx)After each reboot mongo will not start because the permission has gone in /var/runAfter each reboot you could not restart until you make this``` bashmkdir -p/var/run/mongodb/ ;chown -Rmongod:mongod /var/run/mongodb/```**you should better edit your script with the commit mod**```vim /etc/init.d/mongod```thx mwmahlbergfor the fix, I leave this comment for others coming from ggl
Note, this fix has been backported to the v2.6 branch (ddce701ed775996f2a49fc949e26c5bcbc38fe84) and is present in 2.6.5 onward.
https://jira.mongodb.org/browse/SERVER-16721
Can https://jira.mongodb.org/browse/SERVER-3719 be marked as fixed now that this change is in or is there more to do still?
Looks like maybe https://jira.mongodb.org/browse/SERVER-7804 and https://jira.mongodb.org/browse/SERVER-3304 can be marked as resolved now too
Should https://jira.mongodb.org/browse/SERVER-16734 be closed as fixed now?
@benmccann - yes, those tickets are all assigned to Mathias and with fixVersion = next release candidate. They'll be resolved when the RC ships or fixVersion will be bumped.
Cool. Gotcha. Thanks for explaining how the process works
I figured you would mark tickets as fixed when the commit goes into to address them and then release the next RC when all the tickets assigned to that RC are fixed (or bumped to a later RC). If you don't mark them as fixed when the commit goes in, but rather when the RC is released then how do you decide it's time to release the RC?
Oh, looks like they have been marked as resolved now instead of waiting for the RC to ship
Ben, you are correct that tickets are typically resolved at the point whenthe code required to fix them is in master.This can span multiple commitsand/or verification of the fix, so it's not always immediately resolved.The tickets are then typically "closed" once the release is complete.On Fri, Jan 9, 2015 at 11:35 AM, Ben McCann notifications@github.comwrote:> Oh, looks like they have been marked as resolved now instead of waiting> for the RC to ship>> —> Reply to this email directly or view it on GitHub> https://github.com/mongodb/mongo/commit/f58fa5f78a91ce36d8e31d6730ebfdaa6cc1d5ab#commitcomment-9221245> .
This diff doesn't remove V8_HOST_CAN_READ_UNALIGNED define in case of x86/x64 arches (in src/third_party/v8/src/globals.h), is that intended? The binary crashes on x64 with 4.9.2 all the same...
Do i have to add these files
What is the option necessary to make this work?I tried the various settings here:https://jira.mongodb.org/browse/SERVER-965and all fail.
http://docs.mongodb.org/manual/reference/program/mongod/#cmdoption--wiredTigerDirectoryForIndexes
nope - does not work (mongo 3.0.1)returns this error in mongo log:"I STORAGE[initandlisten] exception in initAndListen: 72 Metadata contains unexpected value storage engine option for directoryForIndexesExpected true but got falseinstead, terminating"from this command line:"/usr/local/mongo/bin/mongod --wiredTigerDirectoryForIndexes -f /etc/mongo/mongodb.conf"
what are the contents of your mongodb.conf file?This option is only valid if you are using the WiredTiger storage engine.
# mongodb.confdbpath=/data/wt1logpath=/data/loglogappend=trueport=27017unixSocketPrefix=/tmprest=truehttpinterface=truejournal=truedirectoryperdb=truefork=truereplSet=rs1storageEngine=wiredTigerdirectoryForIndexes=1###
wiredTigerDirectoryForIndexes=1 (instead of directoryForIndexes=1) also fails with same error above
Please see [this comment in SERVER-965](https://jira.mongodb.org/browse/SERVER-965?focusedCommentId=878839&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-878839).
Awesome! Time to remove https://github.com/mongodb-partners/mongo-rocks/blob/master/.clang-format :)BTW are you planning to backport this to 3.0?
@igorcanadiThanks!We are still sorting out a few rough edges, so might want to wait on removing your formatter.At this point, we have no plans to backport to 3.0
@igorcanadi - FYI rough edges have been addressed, it is staying.
Thanks!
t
Thanks, @monkey101 -- this fell through the cracks.
@shreyasp can you email the mongodb-user user group? This is probably not a great venue for troubleshooting your problem.https://groups.google.com/forum/#!forum/mongodb-user
Nice!
:cake: :fireworks: :smile:
I try to update a minutes array(this array is not exist) with upsert & $ positional operator. I need it automatic create a minutes array, but created a minutes object.
Many many thanks! Glad to see that MongoDB listens to their audience :)
What about when globalSec = now?
Hi, and thanks a lot for the fix and comments, so I was able to find it and get my headache off :) I use OpenSuse and installed mongodb as suggested from this repo https://repo.mongodb.org/zypper/suse/11/mongodb-org/3.0/x86_64/Thing is that in my setup this line was not present: https://github.com/mongodb/mongo/commit/50ca596ace0b1390482408f1b19ffb1f9170cab6#diff-9e766216c0a0f6c97a410cc283361eb0R27and had to manually add it in order to have the full fix. Not sure if it got lost somewhere among the branches, so just to let you know. Thanks again.My Mongodb version is 3.0.6
Hey Mathias! Do we need to apply the same patch to MongoRocks, too? Would it make sense to move the test to generic storage_engine tests?
Yes, you'll need to do this in MongoRocks. This would make sense as a generic test, but we don't currently have a way to test oplogs in generic tests, and I don't think that will happen before the 3.2.0 release.
Ive seen a lot of complaints about missing pid dir when running Centos7 / systemdHere is a tip: You should make sure /var/run/mongodb exists byadding a file/etc/tmpfiles.d/mongod.confIt should contain the followingD /var/run/mongodb 0755 mongod mongod -This will ensure that the pid folder always exists. Has worked well for me and seems to be the systemd way of doing it...http://www.freedesktop.org/software/systemd/man/tmpfiles.d.html
Same problem here with OpenSuse and the line missing from the init file! Thanks!
On my system it seems that the logged ip address is from the server ! It should be the client ip.
@ecocode Thanks for reporting this! I can confirm this behaviour, and I've opened a ticket in our issue tracking system to follow it: https://jira.mongodb.org/browse/SERVER-22054
Hi!Is there a more updated list I should be looking at? I'm not finding error codes: 16540 or 16549, which are referenced in Moped error messages:```See https://github.com/mongodb/mongo/blob/master/docs/errors.md for details about this error.```
This file is unfortunately out of date, but you can generate a new one as follows:`buildscripts/errorcodes.py -o errors.md --report=markdown`
Are you sure that the User/Group is mongod and not mongodb ? (On wheezy it's mongodb)
Thanks for the catch, and sorry about the confusion. I hit this in my own testing, and am planning to put the fix to this in with the change. I hope to get the change in in the next ~day or so.
Hi, after an update from mongo 3.0 to 3.2 I get an error on $substr while trying to search inside a collection. I do know how to interpret or fix this error. Any help?
Hi Chririla,I think I can probably explain what's going on. The $substr expression is currently only designed to work correctly on ASCII strings, not UTF-8 strings, see docs here: https://docs.mongodb.org/manual/reference/operator/aggregation/substr/#exp._S_substrWhen $substr is passed a string encoded in UTF-8, it interprets the 'start' and 'length' inputs in terms of number of bytes, even though some UTF-8 characters require multiple bytes to represent one character. This can result in an output that is no longer valid UTF-8. See below for an example in the mongo shell:```> var x = '\uD834\uDF06'> x𝌆> x.length2> x[0]// won't render here, it's an invalid UTF-8 character```The error you saw means that somewhere in your data there is unicode character that is represented by multiple bytes, and your $substr computation created an invalid UTF-8 character. I hope this helps!
Thanks for the response. I think this may be it. I will post the outcome after we modify out code.
Ok. I've filed [SERVER-22580](https://jira.mongodb.org/browse/SERVER-22580) which might help resolve the issue in the future.
Doesn't this mean that the packages for Jessie will _not_ contain the sysvinit script in addition to the systemd service file?Jessie changed the default to systemd, but sysvinit is still actively supported, so it would be neat/helpful if the package contained both to maintain compatibility. :smile:
Interestingly, looks like this commit caused RocksDB to start failing jsCore_small_oplog and jsCore_small_oplog_rs with OOM issues:![screen shot 2016-02-26 at 11 27 04 am](https://cloud.githubusercontent.com/assets/1091023/13362955/ff5c8ade-dc7b-11e5-89e8-f886310aa46a.png)
Here's the test output: https://logkeeper.mongodb.org/build/56cf5f1abe07c44a012dc316/test/56cf5fbbbe07c44a012ddba0?raw=1
JIRA ticket should be:https://jira.mongodb.org/browse/SERVER-23853
Those lines were already in my init file (MongoDB shell version: 3.0.11 on centos 7) but I still had to manually create the folder
Hey @andy10gen, this diff introduced a bunch of failures for me: https://gist.github.com/igorcanadi/1dca04aa6f6506a4ce6ffb5cf5fb72d3.I'm using g++ 4.8.5, is this a known problem?
We raised the compiler minimum to GCC 5.3 in this commithttps://github.com/mongodb/mongo/commit/8d8f17890e5a7e3cb2ea0994ccb58793abdee124backin April.-AndyOn Thu, May 19, 2016, 11:06 PM Igor Canadi notifications@github.com wrote:> Hey @andy10gen https://github.com/andy10gen, this diff introduced a> bunch of failures for me:> https://gist.github.com/igorcanadi/1dca04aa6f6506a4ce6ffb5cf5fb72d3.>> I'm using g++ 4.8.5, is this a known problem?>> —> You are receiving this because you were mentioned.> Reply to this email directly or view it on GitHub> https://github.com/mongodb/mongo/commit/97f24aa42d86dcadd789ba2c9e144709fa7a7aab#commitcomment-17551261
good stuff 👍
Technically, these should be "severe()".
@tychoish this commit breaks majorly!systemd reads the values literally and completely ignores the fact that "#" is a comment.```Oct 01 14:35:15 hostname systemd[1]: [/lib/systemd/system/mongod.service:10] Failed to parse resource value, ignoring: infinity # file sizeOct 01 14:35:15 hostname systemd[1]: [/lib/systemd/system/mongod.service:11] Failed to parse resource value, ignoring: infinity # cpu timeOct 01 14:35:15 hostname systemd[1]: [/lib/systemd/system/mongod.service:12] Failed to parse resource value, ignoring: infinity # virtual memory sizeOct 01 14:35:15 hostname systemd[1]: [/lib/systemd/system/mongod.service:13] Failed to parse resource value, ignoring: 64000 # open filesOct 01 14:35:15 hostname systemd[1]: [/lib/systemd/system/mongod.service:14] Failed to parse resource value, ignoring: 64000 # processes/threadsOct 01 14:35:15 hostname systemd[1]: [/lib/systemd/system/mongod.service:15] Unknown lvalue 'TasksMax' in section 'Service'Oct 01 14:35:15 hostname systemd[1]: [/lib/systemd/system/mongod.service:16] Unknown lvalue 'TasksAccounting' in section 'Service'```
I just did some testing of these values on one system, and I've not been able to reproduce this error yet, but I think that there may be something more happening with different versions of systemd, and I want to dig into this further.I've created https://jira.mongodb.org/browse/SERVER-26438 to track this problem more closely, but I'd like more information about your set up, including (if possible) which distribution and operating system release, as well asand version of systemd you've observed this under.Sorry for the problems, and we'll try and address this as quickly as possible.
Can be easily reproduces with this Vagrant box:```BASE_BOX = "debian/jessie64"BASE_BOX_VERSION = "= 8.2.0"``````vagrant@hostname:~$ cat /etc/os-releasePRETTY_NAME="Debian GNU/Linux 8 (jessie)"NAME="Debian GNU/Linux"VERSION_ID="8"VERSION="8 (jessie)"ID=debianHOME_URL="http://www.debian.org/"SUPPORT_URL="http://www.debian.org/support/"BUG_REPORT_URL="https://bugs.debian.org/"```Sorry don't have a JIRA account, please add it there.
I tried to reproduce this issue on Debian 8.1 system built from the default Debian AMI on amazon, and was not able to reproduce this issue, although if you upgraded to this package from another package, it's possible that I've not reproduced your environment accurately.It looks like the vagrant box version 8.2.0 was released on October 22, 2015, and there have been a number of updates to the "debian/jessie64" box since then. I'm not sure if this is a factor in the behavior that I'm observing.I'm going to update the Jira ticket with some of this information, but if you have more context that might help us understand what's going on, that might be useful in getting to the bottom of this issue.Sorry for the confusion.
May I ask for the reason about this revert??
Please see [this comment](https://jira.mongodb.org/browse/SERVER-21388?focusedCommentId=1165442&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-1165442).Thanks,Ramón.
After I installed the MongoDB(version:3.4.0) on centOS7, I could not find the /etc/init.d/mongod file. So, I created it manually. And pasted the code from github repo (/rpm/init.d-mongod). And then execluded 'chmod 0755 mongod'. Still not working!Anyone help?
@blackmatch I got the same error for centos 7 (my version is 7.3), mongo 3.4I fix it by replacing /etc/systemd/system/multi-user.target.wants/mongod.servicewith this repo newest version of mongo/rpm/mongod.service
@wingzero0 I fix it by creating /lib/tmpfiles.d/mongodb.conf with content "d /var/run/mongodb 0755 mongod mongod". And then reboot.
Im
Z
Zd x
good
thank you!
RIP
@derickr This may seem superfluous, but you may want to stick a few extra tests in:1.A non-Daylight Savings Time datetime for one of the US locations. Christmas would be a safe date to use.2. A July datetime, but before 1918 (when DST was established in the US).The above two will give you the same time. If y'all are using the ICU libraries, this shouldn't be an issue, but you never know with timezones when something will go wonky!
Is the default dbPath still correct? According to the current documentation the default path is "/data/db" [1][1] https://docs.mongodb.com/manual/reference/configuration-options/#storage.dbPath
Yes that's correct by default the mongod will use "/data/db". However, if MongoDB is installed using a package manager, it may come with a config, like this one, that specifies a different data directory. Please feel free to open a [docs ticket](https://jira.mongodb.org/projects/DOCS/summary) or use the feedback bar (bottom right) to help us clarify our documentation around this behavior.
"scheduler"
Trying to report an error.I was running mongodb v3.4.9 with no issue - but when I updated to v3.4.10, nothing works. All I get is member of replica set 1 not being able to connect to the other (according to the mongo logs on port 27017), when it did just fine before. Both servers on same subnet and can other wise 'talk' just fine using graylog, elasticsearch, ssh, etc etc. Just not in mongo anymore.I tried to re-install on straight new install of 3.4.10. I found that removing the brackets on the ip addresses in the bindIp section allowed the db to run using following:mongod --config /etc/mongod.conf --dbpath /var/lib/mongodbhowever, when I tried to login, I got the following:dshirk@netenggraylog01:~$ mongo --host 10.x.x.xMongoDB shell version v3.4.10connecting to: mongodb://10.x.x.x:27017/2017-10-26T12:01:36.067-0600 W NETWORK[thread1] Failed to connect to 10.x.x.x:27017, in(checking socket for error after poll), reason: Connection refused2017-10-26T12:01:36.067-0600 E QUERY[thread1] Error: couldn't connect to server 10.x.x.x:27017, connection attempt failed :connect@src/mongo/shell/mongo.js:237:13@(connect):1:6exception: connect failedWhere do I report this? Thanks! and sorry for the clutter!
Hello @brokerdavelhr,I'm sorry to hear you're experiencing this issue. To report a bug in MongoDB, you can [create an issue in JIRA](https://jira.mongodb.org/secure/Dashboard.jspa), which we use to track work on MongoDB. For MongoDB-related support discussion please post on the [mongodb-user group](https://groups.google.com/group/mongodb-user) or [Stack Overflow with the `mongodb` tag](https://stackoverflow.com/questions/tagged/mongodb).Additionally, see our [Technical Support page](https://docs.mongodb.org/manual/support) for additional support resources.Thanks,Mark
@markbenvenuto: I suppose it wasn't intentional to add a new file during the cherry-pick:src/mongo/s/catalog/sharding_catalog_create_database_test.cppThe same applies for the 3.0 branch: b70b91f98c479d
https://jira.mongodb.org/browse/SERVER-33876
Please suggest, does this commit fixes the issue with authentication messages flooding?
https://jira.mongodb.org/browse/SERVER-34848
:+1: :clap: 
🙌
nice
I can confirm that I am missing `/etc/init.d/mongod` service script used by `sudo service mongod start` on Jessie.```# service mongod startmongod: unrecognized service# ls -l /etc/init.d/total 8-rwxr-xr-x 1 root root 3809 Mar72018 hwclock.sh-rwxr-xr-x 1 root root 1191 May 17 10:56 procps```I am using the [official way](https://docs.mongodb.com/manual/tutorial/install-mongodb-on-debian/) to install MongoDB.I am using the docker image `debian:stable-slim````# uname -aLinux localhost 4.9.93-linuxkit-aufs #1 SMP Wed Jun 6 16:55:56 UTC 2018 x86_64 GNU/Linux# cat /etc/debian_version9.5```
For those following from home, please open a SERVER ticket in https://jira.mongodb.org for any server-related issues. Please be aware that the move from sysvinit to systemd is intentional, so adding sysvinit support to Debian9 packages is unlikely to be prioritized.
@ramonfm ok, just a quick question (I do not want another account), how should I run the mongo service then (I do not want to run it directly using `mongod -f /etc/mongod.conf`)? I do not really care if it is `sysvinit` or `systemd`..And btw, the configuration, `/etc/mongod.conf`, is missing too, I had to create it on my own.
Unfortunately this is not a good forum for this discussion. You can post on http://groups.google.com/group/mongodb-user or http://stackoverflow.com/questions/tagged/mongodb if you have accounts there.
typo: opensl 
typo: deprecared -> deprecated 
Same on line 157
Fixes [SERVER-38647](https://jira.mongodb.org/browse/SERVER-38647).
> MongoDB is free**Not really**
> MongoDB is free**I don't think that means what you think it means.**
> The four essential freedoms> A program is free software if the program's users have the four essential freedoms: [1]>> The freedom to run the program as you wish, for any purpose (freedom 0).> The freedom to study how the program works, and change it so it does your computing as you wish (freedom 1). Access to the source code is a precondition for this.> The freedom to redistribute copies so you can help others (freedom 2).> The freedom to distribute copies of your modified versions to others (freedom 3). By doing this you can give the whole community a chance to benefit from your changes. Access to the source code is a precondition for this.http://www.gnu.org/philosophy/free-sw.html
> The four essential freedoms> A program is free software if the program's users have the four essential freedoms: [1]>> The freedom to run the program as you wish, for any purpose (freedom 0).> The freedom to study how the program works, and change it so it does your computing as you wish (freedom 1). Access to the source code is a precondition for this.> The freedom to redistribute copies so you can help others (freedom 2).> The freedom to distribute copies of your modified versions to others (freedom 3). By doing this you can give the whole community a chance to benefit from your changes. Access to the source code is a precondition for this.http://www.gnu.org/philosophy/free-sw.html
If these descriptions end up being used for generating docs etc, then perhaps worth changing to:Specify the directory for the diagnostic data collection [files]
https://jira.mongodb.org/browse/SERVER-38828
This default is now a configure option in upstream (post 2.7).https://github.com/gperftools/gperftools/commit/5574c87e39ee592c909cb48245c1d91e90ddaf4d
SERVER-31245
SERVER-36226
Why was this fix added only for rpm ? it is happening on other OSes
@ballad89 It looks like when I made this change the Debian service file did not include a `PIDFile=` line, so this was only relevant to RPM. Could you open a SERVER ticket in Jira (https://jira.mongodb.org/secure/Dashboard.jspa) describing the problem you are seeing?
SERVER-41007
The ticket number is 41500, not 414500. 
https://jira.mongodb.org/browse/SERVER-42089
https://jira.mongodb.org/browse/SERVER-42089
how to config it!
@dishytianxiang you can find the documentation for the server parameter here: https://docs.mongodb.com/manual/reference/parameters/#param.oplogInitialFindMaxSecondsYou must set the parameter using [setParameter](https://docs.mongodb.com/manual/reference/parameters/#synopsis). 
Hi @dishytianxiangFor any support questions, please create a post on our [Community Google Group](https://groups.google.com/forum/?nomobile=true#!forum/mongodb-user). That is the best place for support questions like yours. 
ok！ thanks
Note: commit message should be **SERVER-42040**
This commit should have had the description "SERVER-33445". Typo.
Just wanted to say Kudos to the implementer 👏
@vmiheer - Thanks! Someday we hope to get it upstreamed into mainline SCons.
Actually fixes SERVER-46798. Misleading commit message.
@XueruiFa Good stuff!
This doesn't seem quite right, and makes the resulting packages uninstallable: (https://github.com/docker-library/mongo/pull/391#issuecomment-613012081)```console+ apt-get install -y mongodb-org=4.4.0~rc0 mongodb-org-server=4.4.0~rc0 mongodb-org-shell=4.4.0~rc0 mongodb-org-mongos=4.4.0~rc0 mongodb-org-tools=4.4.0~rc0Reading package lists...Building dependency tree...Reading state information...Some packages could not be installed. This may mean that you haverequested an impossible situation or if you are using the unstabledistribution that some required packages have not yet been createdor been moved out of Incoming.The following information may help to resolve the situation:The following packages have unmet dependencies: mongodb-org-tools : Depends: mongodb-database-tools but it is not installableE: Unable to correct problems, you have held broken packages.```Was `mongodb-database-tools` an intentional `Depends` here, or was that supposed to be `Provides` or perhaps just an extra copy/paste that needed more changes?
@tianon - The `mongodb-database-tools` is intended as a depends edge, but it looks like the necessary package files to satisfy the dependency were not yet uploaded to the repo. CC @tychoishand @rychipman.Effectively, we converted `mongodb-org-tools` into a metapackage that depends on `mongodb-database-tools` and `mongodb-org-database-tools-extra`, as those latter two packages now originate from two different projects, and there is no longer an org/com (aka community/enterprise) distinction relevant for the contents of `mongodb-database-tools`.
I don't think this is working properly -- with `<RegistrySearch ... Type="raw" />` above, this `WINDOWSBUILDNUM` value is prefixed with `#` (because it's a `DWORD` value inside the registry; https://wixtoolset.org/documentation/manual/v3/xsd/wix/registrysearch.html), so this is testing `"#10" >= 10`, which I don't think can pass. :confused:I'm rubbish at wix, but I imagine there's bound to be some way to remove the `#` prefix?(This makes the `.msi` for 4.4.0-rc4 impossible to install in my testing. :grimacing:)
This has been fixed in 760cfd020ff0d70d3a50c69c2ec1fe283cca83e5 in https://jira.mongodb.org/browse/SERVER-48015 and the fix will be in 4.4.0-rc5.Unfortunately, there is no easy way to remove the "#" without using a custom action. Fortunately, the registry key `CurrentMajorVersionNumber` was added in Windows 10 so an existence check is all that is needed. 
I know the note above mentions that `VersionNT` is set to a fixed value, but what about `VersionNT64`? (https://docs.microsoft.com/en-gb/windows/win32/msi/versionnt64)It seems to be what's recommended by the wix folks for 64bit versions of Windows: https://wixtoolset.org/documentation/manual/v3/howtos/redistributables_and_install_checks/block_install_on_os.htmlI think it would be something like this:```xml<Condition Message="MongoDB application is only supported on Windows 10/Windows 2016 or later">￼<![CDATA[Installed OR (VersionNT64 >= 1000)]]>￼</Condition>```(That `1000` value is corroborated by https://www.advancedinstaller.com/forums/viewtopic.php?p=93536#p93536 :sweat_smile:)If it would help, I'm happy to file this as a PR or something instead. :+1:
@markbenvenuto doh, sorry, GitHub didn't load your comment (hence my follow-up), and I should've checked master too.Thank you!!
Unfortunately, the problem is that even `VersionNT64` has the same problem and is hardcoded to 603 (see https://support.microsoft.com/en-us/help/3202260/versionnt-value-for-windows-10-and-windows-server-2016). The installer, `msiexec`, does not have a manifest entry to "see" that it is running on Windows 10. See https://docs.microsoft.com/en-us/windows/win32/sysinfo/targeting-your-application-at-windows-8-1 for what I am talking about.I cannot speak to what AdvancedInstaller is doing though.If you run the installer on Windows 10 with a more verbose log, (`msiexec /lvx* out.log /i <msi>`) you will see:```Property(C): VersionNT = 603Property(C): VersionNT64 = 603```@tianon No worries. The fix only was just made today.
SERVER-48073 is the correct ticket number
Unfortunatly the errorcodes.py doesn't have this feature anymore, so there seems to be no way to get the errorcodes in any documentation.https://jira.mongodb.org/browse/DOCS-10757
I think our toolchain should not be that special. I don't think it matters now if we did check, but if it did, that seems like a big problem.
This is basically what I was doing with libc++ in third_party. I wonder - perhaps we might be able to unify those approaches so this is less of a "hack" and more of an "intended library injection" tool?
I am leaning more and more into this needing to be a LIBDEPS tag somehow. These all do the same thing but have different names, and they all imply the same exception in LIBDEPS.
> @dishytianxiang you can find the documentation for the server parameter here: https://docs.mongodb.com/manual/reference/parameters/#param.oplogInitialFindMaxSeconds>> You must set the parameter using [setParameter](https://docs.mongodb.com/manual/reference/parameters/#synopsis).how to confiure for findNetworkTimeout:getMoreNetwork Timeout?i can't find any parameter from ServerParameter?
@leoxu8703 Please see the above comment on the Community Google Group. I no longer work at MongoDB, so the likelihood of having your question answered here is exceedingly slim.
Nice
Nice
This is for `3.6.23`, not `3.6.18` as the commit message suggests.
We have a requirement for benchmark testing in the 4.0.10 version.How can we run the benchmark test now without the perf tool?
@deriamis Why was the python dependency not removed altogether. No file inthe package or rpm scripts in the RPM rely on python that I can tell.
> @deriamis Why was the python dependency not removed altogether. No file in the package or rpm scripts in the RPM rely on python that I can tell.The Compass installer is a Python script, so Python should be a dependency at least somewhere here. That said, it does look like the Python dependency was never in the right place anyway - a fact which I missed in my change. I'll make another change to move the dependency down to the `-tools` package where it should be.
@deriamis Thanks, that makes sense.I was trying to work out where it came from in the first place.
is scons_cache_scope tag supported in v3.x?
Since we are running into some CentOS8 combination issue, had to go through this diff. But Can you please letus know if scons_cache_scope tag supported in v3.x? Because searching this tag in v3.6 branch doesn't give any references in the build scripts. But i see the code in 4.x onwards. Is it a merge issue?
Not sure if we can use nonWildcardMultikeyPaths here.
W
