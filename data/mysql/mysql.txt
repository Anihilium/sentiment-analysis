This doesn't handle null values; now there is no distinction between null and the empty string. Try:client.query('SELECT NULL as field_a, NULL as field_b, "" AS field_c', function(err, results) {if (err) throw err;assert.strictEqual(results[0].field_a, null);assert.strictEqual(results[0].field_b, null);assert.strictEqual(results[0].field_c, '');client.end();});
Fixed in: 10e81c252e6a9f3d83e9d05a8e8f693a2756784c
Is there a specific reason why BLOB's aren't cast into buffers?
My original patch contained support for casting blobs to buffers. Maybe there is a plan for implementing it differently? I dunno.
Yeah, I didn't do that part yet because it is hard to do efficiently. I need to talk to ryan to see if we can do better than that, but otherwise yes - this is coming back in. If any of you guys needs it right now, ping me and I'll put the naive implementation back in.
Doesn't this create a memory problem for large result sets?
It's not a bug - it's a feature! I mean in a lot of cases it is very convenient to buffer all result rows, but it is entirely optional. If you don't pass a callback to the `.query()` function, no result set buffering takes place and you only get individual `'row'` events.But maybe I'm missing something and you're saying there is a memory leak here?
I see. Did not see you always return the query object so one can handle the events themselves.Impressive work!
Thanks Malte! I'm using the same pattern in `formidable` (passing a callback causes buffering). It's certainly not obvious from a user perspective, so I think a little work needs to go into promoting this approach. I'll write a little blog post about it.In the future I would like to go even further and allow streaming the row values themselves, but that's even harder in terms of finding a nice API for it (most folks wouldn't want this behavior by default).
Hmm, maybe if one is coming from an ActiveRecord like background. When working with cursors, receiving a callback per row feels natural. Then again this can always be handled on the level above as long as the raw API is exposed.
Well, not everybody is as streamie as you, jed and me : ).
You can write to me, when this part of the improvements will be completed, I will update the [node-mysql-bindings-benchmark](http://github.com/Sannis/node-mysql-bindings-benchmarks) :)Any comments are welcome.
For now I just picked some low hanging fruits that were easy to spot. Hopefully I'll have time to do some full profiling soon to see if there is more performance to be gained. I'll let you know.
<code>POWS[packet.index]</code> can also be written <code>1 << (packet.index << 3)</code> if you want to avoid multiplication (or <code>1 << (packet.index \* 8)</code> if you want it readable). but the lookup table is probably as fast :)
Cal: I just tried that, but it doesn't seem to be any faster. Do you see any reason why it should be faster than a property lookup?
It should be faster than the power op, but probably no faster than a property lookup in practice - they're both very very simple ops. I did a quick benchmark:```2 shifts : 273 per µs (microsecond)lookup: 201 per µspower:23 per µs```so i think the lookup is just fine :D
Yeah, I still hope to find some major performance bottlenecks - right now this driver is still an order of magnitude slower than the C competition, and I don't think it should be that slow : ).
Not sure if this is related to the staging area, but this is not the issue, so I write here.I used this code to benchmarking reconnect of node-mysql:```start_time = new Date();function reconnectAsync() {i += 1;if (i <= cfg.reconnect_count) {conn.end();conn.connect(function (err, result) {reconnectAsync();});} else {total_time = ((new Date()) - start_time) / 1000;sys.puts("**** " + cfg.reconnect_count + " async reconnects in " + total_time + "s (" + Math.round(cfg.reconnect_count / total_time) + "/s)");insertAsyncBenchmark(callback, cfg);}}reconnectAsync();```So I change it to:```start_time = new Date();function reconnectAsync() {i += 1;if (i <= cfg.reconnect_count) {conn.end(function () {conn.connect(function (err, result) {reconnectAsync();});});} else {total_time = ((new Date()) - start_time) / 1000;sys.puts("**** " + cfg.reconnect_count + " async reconnects in " + total_time + "s (" + Math.round(cfg.reconnect_count / total_time) + "/s)");insertAsyncBenchmark(callback, cfg);}}reconnectAsync();```But `connect` doesn't work after `end`. Is this right behavior?http://github.com/Sannis/node-mysql-bindings-benchmarks/commit/519d6615ab0a8d3ccfe59875bfa7d42cf7c4ddf0
I just fixed the reconnect behavior in 2db5bbdb449686733290390cb3c196d9af3d43be. Your benchmark should now work.Anyway, also test `client.destroy()` as that is now behaving like `client.end()` used to behave. I would expect `client.end()` to be a good bit slower, but I guess you will see for yourself : ).
Thanks, it works.I added a benchmark with client.destroy () in Sannis/node-mysql-bindings-benchmarks@ad86b0f982b8c8ffd24b45dfbfe4ce6832239a52.Yep, client.destroy() is 20-50% faster than client.end(), but this rate is unstable, because I have to run with a small number of reconnects. DNS resolving is used when connecting, and my server can not cope with so many queries :-) It's a bit strange, so I will think over this point. I have long been thought to use the unix socket, to ignore the network operation, even if they are local.```Benchmarking CPP-MySQL:1000 sync reconnects in 0.07s (14285/s)Benchmarking PHP-MySQL:1000 sync reconnects in 0,27s (3666/s)Benchmarking Sannis-node-mysql-libmysqlclient:1000 sync reconnects in 0.368s (2717/s)Benchmarking felixge-node-mysql:1000 async reconnects with .end() in 1.517s (659/s)1000 async reconnects with .destroy() in 0.989s (1011/s)```
Is there any reason why this function, unlike all others is attached directly to Client rather than to Client.prototype?
Yeah, it doesn't depend on the state of a client instance, so this makes it "class method" in my book. How would you do it?
interesting, I imagine the lookup is a bit costly since it has to traverse a few scopes but 22%?? awesome!
Yeah, Tim-smart mentioned something about this to me a while back when I was working on a new websocket parser.
I guess its all relative, compared to the rest of your app it might not make much of a difference at all, but pretty easy optimization to squeeze out
Yeah, I wouldn't take this optimization _anywhere_ else, but this switch statement is literally executed millions of times, so it makes sense here. There are a few other micro-optimizations like this that I have found, but they're not worthwhile compared to this. I'm still hoping to find some bigger opportunities to gain more speed. At this point this module is ~7x slower for SELECT and ~2x slower for INSERT compared to PHP.
ah, that explains it :)
I'm just curious, what if array of functions indexed by state is used? At least in C it would be good optimization for a big switch.
It turns out it's ~60% faster than using a plain variable as this test shows: http://jsperf.com/variable-tree-lookup
vgrichina: Just tried it, it's just about the same speed it seems.
I think it's because you were looking up the property of an object which probably make v8 opt out of inlining the statement. The difference in those raw operations would not be 20% :)
yeah good call, if they are numeric and _not_ properties I could see v8 inlining them, but even eval() could get in the way of that I'd imagine
eval breaks pretty much all optimizations :)
yup lol
Great, I'll update [node-mysql-bindings-benchmarks](http://github.com/Sannis/node-mysql-bindings-benchmarks) at this evening.
Please push this newest version to NPM as soon as possible... I really need this array handling ability in a current project.
I agree. Please push to NPM.
+1 to pushing to npm
How can I put the new password? MySQL version? Re-make the user?Edit 1: Is the Hashing?
Does this pass the test suite?
There should be a test for this.
OK, I'll do it in a moment.
You were right about the test. It made me realize the stupidity of my change :smile: I'll update it now.
Great work man. Thank you so much. :heart: :heart: :heart:
Why does `'drain'` take an `err` argument here? I think this is copy & paste failure, isn't it? : p
LGTM, good work. Did you also add a note to the docs?UPDATE: never mind, I see you did. Awesome!
Yeah.. you got me! :P
Fixed.
You should create a new class called `Field` for this as v8 really loves named constructors for hidden class optimizations. It also adds more structure to things, which I like.
:hammer: sweet!
No, thank you guys.That's an awesome turn around!Sorry for being absent in the earlier request for a use case.My particular use case was that I needed to get 3M rows of data out of Mysql and then pass it to another batch API.The data had to be chunked < 1000 rows for the batch API.So i looped through keys (id < 1000,id > 1000 < 2000,etc).But with 3M rows and growing that's > 3K queries that have to get queued up before any work starts and the foot print is more significant and not fixed.
:watermelon: lawlz
lol
:+1:
![Tabs](https://gimmebar-assets.s3.amazonaws.com/4d288c2806362.png)
:heart:
Looks like this fails for large files due to an EPIPE exception. Can "packets" be streams?``` javascriptvar fs = require('fs');var mysql = require('mysql');var connection = mysql.createConnection({host: 'localhost', user: 'admin', debug: true});var table = 'load_data_test';connection.query('DROP DATABASE tmp');connection.query('CREATE DATABASE tmp');connection.query('USE tmp');connection.query(['CREATE TEMPORARY TABLE `' + table + '` (','`id` int(11) unsigned NOT NULL AUTO_INCREMENT,','`title` varchar(255),','PRIMARY KEY (`id`)',') ENGINE=InnoDB DEFAULT CHARSET=utf8'].join('\n'));var path = '/tmp/tmp.sql';var stream = fs.createWriteStream(path, {flags: 'w'});stream.on('close', function() {var sql ='LOAD DATA LOCAL INFILE ? INTO TABLE ' + table + ' ' +'FIELDS TERMINATED BY ? (id, title)';var ok;connection.query(sql, [path, ','], function(err, _ok) {if (err) {console.error(err);throw err;}});});for (var i = 0; i < 100000; ++i) {stream.write(i + ',' + i + ': The quick brown fox jumps over some stuff\n');}stream.end();```produces:```<-- HandshakeInitializationPacket{ protocolVersion: 10,serverVersion: '5.5.15',threadId: 6955,scrambleBuff1: <Buffer 47 56 59 3c 60 4e 48 5b>,filler1: <Buffer 00>,serverCapabilities1: 63487,serverLanguage: 8,serverStatus: 2,serverCapabilities2: 32783,scrambleLength: 21,filler2: <Buffer 00 00 00 00 00 00 00 00 00 00>,scrambleBuff2: <Buffer 72 4d 67 41 4e 42 40 5c 2e 6c 5a 5e>,filler3: <Buffer 00>,pluginData: 'mysql_native_password' }--> ClientAuthenticationPacket{ clientFlags: 193487,maxPacketSize: 0,charsetNumber: 33,filler: undefined,user: 'admin',scrambleBuff: <Buffer >,database: undefined }<-- OkPacket{ fieldCount: 0,affectedRows: 0,insertId: 0,serverStatus: 2,warningCount: 0,message: '',changedRows: 0 }--> ComQueryPacket{ command: 3, sql: 'DROP DATABASE tmp' }<-- OkPacket{ fieldCount: 0,affectedRows: 0,insertId: 0,serverStatus: 258,warningCount: 0,message: '',changedRows: 0 }--> ComQueryPacket{ command: 3, sql: 'CREATE DATABASE tmp' }<-- OkPacket{ fieldCount: 0,affectedRows: 1,insertId: 0,serverStatus: 2,warningCount: 0,message: '',changedRows: 0 }--> ComQueryPacket{ command: 3, sql: 'USE tmp' }<-- OkPacket{ fieldCount: 0,affectedRows: 0,insertId: 0,serverStatus: 2,warningCount: 0,message: '',changedRows: 0 }--> ComQueryPacket{ command: 3,sql: 'CREATE TEMPORARY TABLE `load_data_test` (\n`id` int(11) unsigned NOT NULL AUTO_INCREMENT,\n`title` varchar(255),\nPRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8' }<-- OkPacket{ fieldCount: 0,affectedRows: 0,insertId: 0,serverStatus: 2,warningCount: 0,message: '',changedRows: 0 }--> ComQueryPacket{ command: 3,sql: 'LOAD DATA LOCAL INFILE \'/tmp/tmp.sql\' INTO TABLE load_data_test FIELDS TERMINATED BY \',\' (id, title)' }<-- ResultSetHeaderPacket{ fieldCount: null, extra: '/tmp/tmp.sql' }--> LocalDataFilePacket{ data: '0,0: The quick brown...<snip>--> EmptyPacket{}{ [Error: write EPIPE] code: 'EPIPE', errno: 'EPIPE', syscall: 'write', fatal: true }/tmp.js:30throw err;^Error: write EPIPEat errnoException (net.js:769:11)at Object.afterWrite (net.js:593:19)--------------------at Query.Sequence (node_modules/mysql/lib/protocol/sequences/Sequence.js:15:21)at new Query (node_modules/mysql/lib/protocol/sequences/Query.js:11:12)at Protocol.query (node_ratchet/node_modules/mysql/lib/protocol/Protocol.js:41:24)at Connection.query (node_ratchet/node_modules/mysql/lib/Connection.js:90:25)at null.<anonymous> (tmp.js:27:18)at EventEmitter.emit (events.js:93:17)at WriteStream.flush (fs.js:1517:12)at Object.oncomplete (fs.js:297:15)```
I created a getConnection() wrapper function that checks the health of the mysql connection before returning it to the caller and re-establishes the connection as necessary.In my testing it has handled fatal and non-fatal connection issues transparently for the application.If the connection simply timed out, the application recovers without experiencing any errors.If there is a transient but fatal database connection problem, the application will resume functioning automatically as soon as database connectivity is available again.Here is the contents of a file I have named "database.js":``` javascriptvar mysql = require("mysql");var CONFIG = require(__dirname + "/configuration");module.exports.getConnection = function() {// Test connection health before returning it to caller.if ((module.exports.connection) && (module.exports.connection._socket)&& (module.exports.connection._socket.readable)&& (module.exports.connection._socket.writable)) {return module.exports.connection;}console.log(((module.exports.connection) ?"UNHEALTHY SQL CONNECTION; RE" : "") + "CONNECTING TO SQL.");var connection = mysql.createConnection({host: CONFIG.db.host,user: CONFIG.db.user,password : CONFIG.db.password,database : CONFIG.db.database,port: CONFIG.db.port});connection.connect(function(err) {if (err) {console.log("SQL CONNECT ERROR: " + err);} else {console.log("SQL CONNECT SUCCESSFUL.");}});connection.on("close", function (err) {console.log("SQL CONNECTION CLOSED.");});connection.on("error", function (err) {console.log("SQL CONNECTION ERROR: " + err);});module.exports.connection = connection;return module.exports.connection;}// Open a connection automatically at app startup.module.exports.getConnection();// If you've saved this file as database.js, then get and use the// connection as in the following example:// var database = require(__dirname + "/database");// var connection = database.getConnection();// connection.query(query, function(err, results) { ....```
So, `bignumber.js` can accept numbers in, say, hex format. Wouldn't it be more performant to check if the number looks out-of-bounds before the for loop and if so simply construct a hex string of the number and give it to `BigNumber` once, otherwise construct the JavaScript number with the for loop? Or maybe just always parse as a hex string and let JavaScript decompose it.Perhaps something like (rough example; tested fine):``` javascriptvar hex = '';var value;for (var bytesRead = 0; bytesRead < length; bytesRead++) {hex = this._buffer.toString('hex', this._offset, this._offset + 1) + hex;this._offset++;}value = parseInt(hex, 16);return value >= IEEE_754_BINARY_64_PRECISION ? (require("bignumber.js"))(hex, 16).toString() : value;```
:+1:
No update on the Changes file?
Oops, that's my bad. First time bumping versions in this project. I will update the changes file.
It's just Pool, I bumped version before you 1 or 2 days :)
@bhafer The only concern I have here is that your entire app shares a single connection, right?This means if you get 100 requests or have a couple people running some reports that take a bit process, your single DB connection could become a pretty big bottleneck, right?Any clever ways around this?
@anthonywebb you would need to use a pool of connections or make a new connection for each request, whichever is better for your use-case.
@dougwilson do yo know of anyone who is doing something like that above with the new pool support that was added?I've been looking at the pool stuff but am not wild about having to manually release the connection each time a db call is complete, feels like that should just happen in the background automatically?
I use a pool, though I haven't used the pool that was just added here, rather a custom pool using the `generic-pool` node module. I still have to release the connection back to the pool, of course, there is no way around that in an evented system like node since the pool could never know when you are finished with the connection otherwise (like reaching the end of a scope in procedural runtimes).If you don't care about transactions or other MySQL session state (like local variables, local settings, etc.) then you could just use a wrapper that gets a connection from the pool, makes a single query, and releases the connection back to the pool before sending the query results to the caller of the wrapper.``` javascript// Example; not tested// Closes over `pool` variable which is a MySQL pool objectfunction runQuery(stmt, bind, callback) {if (arguments.length === 2) {callback = bind;bind = [];}pool.getConnection(function (error, connection) {if (error) return callback(error);connection.query(stmt, bind, function () {connection.end();callback.apply(null, arguments);});});}```
@dougwilson with the old 0.9.6 version I used a module here: https://github.com/Kijewski/node-mysql-poolIf you look at the readme, what has nice is I never had to release anything.Just could query away and it would handle the connection lifecycle.Have it deployed to some pretty major installs and it is pretty flawless.It doesnt work with more recent versions of node-mysql.So I am on the hunt for something else.I could worry about wrapping every query in pool.getConnection() and connection.end() but it seems silly.
@anthonywebb I updated my comment above with a function that will run a single query from the new built-in pool where you don't have to worry about returning anything to the pool. Just note cavets about doing something like this you cannot use transactions and other session state (the save cavets apply to `node-mysql-pool` there, so I guess you won't see anything different).
@anthonywebb Yes, this does not address pooling.But the example in the code is a single connection example as well, and it is this example I am offering a suggestion about because: a) the example doesn't seem to work at all as written, and b) even if it were corrected, it doesn't seem conceived to handle the possible connection issue scenarios well.The snippet I've included above is a robust, working DB wrapper that provides a reliable, resilient single DB connection.There are pooling libraries, as others have noted, though I've not implemented any so I can't address the best way to do it; presumably they might be able to wrap and pool the recovery logic shared above.
The main reason the example in the README does not work is because `connection = mysql.createConnection(connection.config);` does nothing. `connection` is not the global connection variable, as expected in the example, rather it is the name of the first argument of `handleDisconnect`.
An added benefit of registering the connection object inside the query object is the ability to close it directly within the query callback.This raises a question whether the connection object reference should be declared with an underscore or not.``` jsmysql.createConnection(options).query(sqlTxt,function(err,d) {process(err,d);this._connection.end();});```
I agree it can get handy and also agree that if you want to expose it in the callback remove the underscore because it's not something "internal".
This is breaking lots of code for us, we now have to check if each date column actually returns a date object or not :(
This should only happen on invalid dates. How did you treat invalid dates before?
Yay :palm_tree:
:) thanks for the catch @dougwilson
This is sync? I thought this had to be async :)
It's magic! Basically the statement is not prepared yet when the `prepare()` function returns, this happens async in the background. However, you can already call query() on the returned statement, and the actual query will execute once the prepare is done. If the prepare has an error, the error goes to the query.Not sure if this is the right / perfect API, but it seemed to fit well with how the lib is working so far. What ya think?
I love it, no need to add another level, just call prepare and query right after :)
Build failing since this commit.
Has the fix been included in a build and if so what is the earliest version it was included in? I'm running v0.10.21 and
It's included in 2.0.0-alpha9
:+1:
Congratulations guys!PS: don't forget to update changelog please :)
Thanks! (me updating changelog)
Thanks guys, i am waiting for this release..
AFAIK this can be moved down to line 69, as everything above there will keep the domain (due to either core support, or `Connection` support). This would be prevent a double-bind on all the non-queued cases that way.
ok sounds right to me
This means it's no longer possible to override `createConnection`, although it's still specified in the documentation as working:https://github.com/felixge/node-mysql#pool-options-[Unknown]
Thank you, this has been removed from the documentation.
createSecurePair is deprecated in v0.11.x.You're probably better off just doing something like this for v0.10+ instead:``` javascriptvar wrappedSock = tls.connect({key: this.config.ssl.key,cert: this.config.ssl.cert,passphrase: this.config.ssl.passphrase,ca: this.config.ssl.ca,socket: this._socket}, onSecure);wrappedSock.pipe(this._protocol);// write to wrappedSock and not this._socket from here on out ...```
Thanks, I'll try this! (also in node-mysql2 as the code is the same)
created issue for this - https://github.com/felixge/node-mysql/issues/737
Why is this custom startTLS code necessary? Why not just use `tls.connect({ socket: this._socket, ... }, onSecure);` to upgrade the socket? That functionality exists even in v0.8.x. It should work for v0.11+ as well.
This was just an extension of the code that was contributed ;) I'll look into replacing it with `tls.connect`.
P.S. A PR is always welcome!
@mscdex nevermind, I have already swapped it to `tls.connect` on my local machine! I see a "wrinkle" right now in that `tls.connect` will verify the hostname on the certificate; I need to research to see if this is a valid default or not for MySQL servers.
Looks like no MySQL hosts out there support hostname verification by default (perhaps people's own setups may, but not third-party services). Unfortunately `tls.connect` has no way to opt into certificate verification without CN/SAN verification...
This will be an endlessly moving target; there is no version declaration.
oops, already pushed to master. I'll change to 1.2
I have reverted this commit until you can declare which versions of io.js are actually supported and we don't suddenly start failing when 2.0 comes out, which this commit will cause.
Ok. If you do, please update `package.json` to specify that 1.0 and 1.1 of io.js are not supported.
I'll use this in mysql2 if you don't mind :)
Please do :) I'm 99% sure the Node.js community stole setting up istanbul + coveralls.io from me last year :) And it's been awesome to see people interested in getting code coverage going :D
P.S. I may make tweaks to the config once it actually starts running on AppVeyor :) So far this configuration was based off Express.js stuff and the MySQL parts are all just guesses D:
thanks :) I'll wait for first test results
:disappointed: https://youtu.be/xeKMS62GrTI@jperras but "both" is too much. lol
:+1:
\o/
can this be called out of order? Two compressed packets arrive one after another, cp1, cp2 => cp1.inflate called, cp2 .inflate called; cp2.inflate pushes result before cp1 ?
This still needs a lot of tests added, but this impl will only allow a single outstanding inflate at a time, which is what the `_inflating` guard is doing.
